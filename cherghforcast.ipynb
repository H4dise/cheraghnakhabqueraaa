{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94c887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import jdatetime\n",
    "import holidays\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d733e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Date Conversion Function (Corrected)\n",
    "def persian_to_gregorian(persian_date):\n",
    "    \"\"\"Converts a Persian date string to a Gregorian date string.\"\"\"\n",
    "    year, month, day = map(int, persian_date.split('-'))\n",
    "    persian_datetime = jdatetime.datetime(year, month, day)\n",
    "    gregorian_datetime = persian_datetime.togregorian()\n",
    "    return gregorian_datetime.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122f69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Load Data and Apply Date Conversion\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df['ds'] = df['date'].apply(persian_to_gregorian)\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df['y'] = df['sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce904272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   sale         ds      y\n",
      "0  1399-05-30  384.0 2020-08-20  384.0\n",
      "1  1399-05-31  393.0 2020-08-21  393.0\n",
      "2  1399-06-01  414.0 2020-08-22  414.0\n",
      "3  1399-06-02  410.0 2020-08-23  410.0\n",
      "4  1399-06-03  398.0 2020-08-24  398.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    114 non-null    object        \n",
      " 1   sale    114 non-null    float64       \n",
      " 2   ds      114 non-null    datetime64[ns]\n",
      " 3   y       114 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 3.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2bf16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Lag Features\n",
    "df['Sales_lag1'] = df['sale'].shift(1)\n",
    "df['Sales_lag7'] = df['sale'].shift(7)  # Sales from 1 week ago\n",
    "df.fillna(0, inplace=True) # Fill NaN values\n",
    "\n",
    "\n",
    "\n",
    "#4.Stationary\n",
    "def check_stationarity(series, max_diff=2):\n",
    "\n",
    "    d = 0  # Number of differencing applied\n",
    "    stationary_series = series.copy() # So the code doesn't affect you series\n",
    "\n",
    "    while d <= max_diff: # To check stationary\n",
    "        result = adfuller(stationary_series.dropna()) # Remove that none value\n",
    "        print(f'Differencing {d}:') # To see and show number\n",
    "        print('ADF Statistic: %f' % result[0])\n",
    "        print('p-value: %f' % result[1])\n",
    "        print('Critical Values:')\n",
    "        for key, value in result[4].items():\n",
    "            print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "        if result[1] <= 0.05: # check and know if correct\n",
    "            print(\"Series is stationary after\", d, \"differencing(s)\")\n",
    "            return stationary_series, d\n",
    "\n",
    "        else:\n",
    "            if d < max_diff: # if the maximum diff is reach, the user has already select the maxium amount to convert, so print it\n",
    "                stationary_series = stationary_series.diff().dropna()\n",
    "                d += 1\n",
    "            else:\n",
    "                print(\"Series could not be made stationary within the maximum differencing limit.\")\n",
    "                return None, d  # Indicate failure\n",
    "\n",
    "    return None, d # Indicates fail to return for max diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0c6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differencing 0:\n",
      "ADF Statistic: -2.977901\n",
      "p-value: 0.037010\n",
      "Critical Values:\n",
      "\t1%: -3.498\n",
      "\t5%: -2.891\n",
      "\t10%: -2.582\n",
      "Series is stationary after 0 differencing(s)\n",
      "Number of differencing applied: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage (replace df['Sales'] with your actual sales column)\n",
    "stationary_sales, d_value = check_stationarity(df['sale'])\n",
    "if stationary_sales is not None:\n",
    "    print(\"Number of differencing applied:\", d_value)\n",
    "else:\n",
    "    print(\"Could not make sales stationary\")\n",
    "    # 5. Holiday Features\n",
    "def add_holiday_features(df, country_code='IR'):\n",
    "    # Get holidays for the specified country\n",
    "    country_holidays = holidays.country_holidays(country_code, years=df['ds'].dt.year.unique().tolist())\n",
    "\n",
    "    # Create a holiday feature\n",
    "    df['holiday'] = df['ds'].apply(lambda date: 1 if date.to_pydatetime().date() in country_holidays else 0)\n",
    "\n",
    "    # Create features for days leading up to and after holidays (e.g., window of 3 days)\n",
    "    window = 3\n",
    "    for n in range(1, window + 1):\n",
    "        df[f'holiday_plus_{n}'] = df['ds'].apply(lambda date: 1 if (date + pd.Timedelta(days=n)).to_pydatetime().date() in country_holidays else 0)\n",
    "        df[f'holiday_minus_{n}'] = df['ds'].apply(lambda date: 1 if (date - pd.Timedelta(days=n)).to_pydatetime().date() in country_holidays else 0)\n",
    "    return df\n",
    "\n",
    "df = add_holiday_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174d9ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define SMAPE metric\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98117b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 19, Test size: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38, Test size: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 57, Test size: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 76, Test size: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95, Test size: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:07:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Scores for each fold: [np.float64(5.348011032031598), np.float64(18.182943946706978), np.float64(14.884162030832627), np.float64(13.27805161673333), np.float64(23.211511696087143)]\n",
      "Mean SMAPE Score: 14.980936064478334\n"
     ]
    }
   ],
   "source": [
    "# 7. Time Series Split for Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)  # Adjust n_splits as needed\n",
    "\n",
    "smape_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(df):\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "    print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")  # Debugging: Check sizes\n",
    "\n",
    "    # 8. Train Prophet Model\n",
    "    model = Prophet()\n",
    "\n",
    "    model.add_regressor('holiday')\n",
    "    model.add_regressor('holiday_plus_1')\n",
    "    model.add_regressor('holiday_minus_1')\n",
    "    model.add_regressor('holiday_plus_2')\n",
    "    model.add_regressor('holiday_minus_2')\n",
    "    model.add_regressor('holiday_plus_3')\n",
    "    model.add_regressor('holiday_minus_3')\n",
    "    model.add_regressor('Sales_lag1')\n",
    "    model.add_regressor('Sales_lag7')\n",
    "\n",
    "    model.fit(train_df[['ds', 'y', 'holiday', 'holiday_plus_1', 'holiday_minus_1', 'holiday_plus_2', 'holiday_minus_2', 'holiday_plus_3', 'holiday_minus_3','Sales_lag1','Sales_lag7']])\n",
    "\n",
    "    # 9. Make Future DataFrame\n",
    "    future = model.make_future_dataframe(periods=len(test_df))\n",
    "    future = add_holiday_features(future)  # Ensure holiday features are in future dataframe\n",
    "    future['Sales_lag1'] = train_df['Sales_lag1'].iloc[-1]  # Example: last known value\n",
    "    future['Sales_lag7'] = train_df['Sales_lag7'].iloc[-1]\n",
    "\n",
    "    # 10. Predict\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # 11. Evaluate\n",
    "    y_true = test_df['y'].values\n",
    "    y_pred = forecast['yhat'].tail(len(test_df)).values\n",
    "\n",
    "    smape_score = smape(y_true, y_pred)\n",
    "    smape_scores.append(smape_score)\n",
    "\n",
    "print(\"SMAPE Scores for each fold:\", smape_scores)\n",
    "print(\"Mean SMAPE Score:\", np.mean(smape_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb54740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future sales predictions saved to output.csv\n",
      "         date        sale\n",
      "0  1399-09-22  352.522473\n",
      "1  1399-09-23  353.142740\n",
      "2  1399-09-24  354.579030\n",
      "3  1399-09-25  355.786375\n",
      "4  1399-09-26  367.554832\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jdatetime\n",
    "\n",
    "import pandas as pd\n",
    "import jdatetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# 12. Generate Future Dates for Prediction (30 days from the end of the dataset)\n",
    "last_date = df['ds'].max()\n",
    "future_dates = [last_date + timedelta(days=i) for i in range(1, 31)]\n",
    "future_df = pd.DataFrame({'ds': future_dates})\n",
    "\n",
    "# 13. Add Holiday Features to Future Dates\n",
    "future_df = add_holiday_features(future_df)\n",
    "\n",
    "# Add lag features with last known values\n",
    "future_df['Sales_lag1'] = df['Sales_lag1'].iloc[-1]  # Example: last known value\n",
    "future_df['Sales_lag7'] = df['Sales_lag7'].iloc[-1]\n",
    "\n",
    "# 14. Predict Future Sales\n",
    "forecast = model.predict(future_df)\n",
    "\n",
    "# Prepare DataFrame with Gregorian dates and predicted sales\n",
    "output_df = pd.DataFrame({\n",
    "    'date_gregorian': forecast['ds'],\n",
    "    'sale': forecast['yhat']\n",
    "})\n",
    "\n",
    "# Convert Gregorian dates to Persian (Jalali) calendar\n",
    "def gregorian_to_persian(gregorian_date):\n",
    "    jdate = jdatetime.date.fromgregorian(date=gregorian_date.date())  # Extract date part only\n",
    "    return jdate.strftime('%Y-%m-%d')\n",
    "\n",
    "output_df['date'] = output_df['date_gregorian'].apply(gregorian_to_persian)\n",
    "\n",
    "# Keep only Persian date and sale columns as required\n",
    "output_df = output_df[['date', 'sale']]\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv('output.csv', index=False)\n",
    "\n",
    "print(\"Future sales predictions saved to output.csv\")\n",
    "print(output_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
